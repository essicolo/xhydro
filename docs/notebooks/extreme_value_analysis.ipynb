{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "# Basic imports\n",
    "import hvplot.xarray\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xdatasets as xd\n",
    "\n",
    "import xhydro as xh\n",
    "import xhydro.frequency_analysis as xhfa\n",
    "from xhydro.extreme_value_analysis.parameterestimation.fit import fit\n",
    "import xclim.indices.stats as stats # TODO: DELETE FROM EXAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = (\n",
    "    xd.Query(\n",
    "        **{\n",
    "            \"datasets\": {\n",
    "                \"deh\": {\n",
    "                    \"id\": [\"020*\"],\n",
    "                    \"regulated\": [\"Natural\"],\n",
    "                    \"variables\": [\"streamflow\"],\n",
    "                }\n",
    "            },\n",
    "            \"time\": {\"start\": \"1970-01-01\", \"minimum_duration\": (15 * 365, \"d\")},\n",
    "        }\n",
    "    )\n",
    "    .data.squeeze()\n",
    "    .load()\n",
    ")\n",
    "\n",
    "# This dataset lacks some of the aforementioned attributes, so we need to add them.\n",
    "ds[\"id\"].attrs[\"cf_role\"] = \"timeseries_id\"\n",
    "ds[\"streamflow\"].attrs = {\n",
    "    \"long_name\": \"Streamflow\",\n",
    "    \"units\": \"m3 s-1\",\n",
    "    \"standard_name\": \"water_volume_transport_in_river_channel\",\n",
    "    \"cell_methods\": \"time: mean\",\n",
    "}\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some examples\n",
    "timeargs = {\n",
    "    \"spring\": {\"date_bounds\": [\"02-11\", \"06-19\"]},\n",
    "    \"summer\": {\"doy_bounds\": [152, 243]},\n",
    "    \"fall\": {\"month\": [9, 10, 11]},\n",
    "    \"winter\": {\n",
    "        \"season\": [\"DJF\"],\n",
    "        \"freq\": \"YS-DEC\",\n",
    "    },  # To correctly wrap around the year, we need to specify the resampling frequency.\n",
    "    \"august\": {\"month\": [8]},\n",
    "    \"annual\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we hide years with more than 15% of missing data.\n",
    "ds_4fa = xh.indicators.get_yearly_op(\n",
    "    ds, op=\"max\", timeargs=timeargs, missing=\"pct\", missing_options={\"tolerance\": 0.15}\n",
    ")\n",
    "\n",
    "ds_4fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask beforehand\n",
    "import random\n",
    "\n",
    "nyears = np.unique(ds.time.dt.year).size\n",
    "dom_start = xr.DataArray(\n",
    "    np.random.randint(1, 30, size=(nyears,)).astype(\"str\"),\n",
    "    dims=(\"year\"),\n",
    "    coords={\"year\": np.unique(ds.time.dt.year)},\n",
    ")\n",
    "dom_end = xr.DataArray(\n",
    "    np.random.randint(1, 30, size=(nyears,)).astype(\"str\"),\n",
    "    dims=(\"year\"),\n",
    "    coords={\"year\": np.unique(ds.time.dt.year)},\n",
    ")\n",
    "\n",
    "mask = xr.zeros_like(ds[\"streamflow\"])\n",
    "for y in dom_start.year.values:\n",
    "    # Random mask of dates per year, between April and June.\n",
    "    mask.loc[\n",
    "        {\n",
    "            \"time\": slice(\n",
    "                str(y) + \"-04-\" + str(dom_start.sel(year=y).item()),\n",
    "                str(y) + \"-06-\" + str(dom_end.sel(year=y).item()),\n",
    "            )\n",
    "        }\n",
    "    ] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the indexer will be used to identify the variable created here\n",
    "timeargs_custom = {\"custom\": {}}\n",
    "\n",
    "# We use where() to mask the data that we want to ignore\n",
    "masked = ds.where(mask == 1)\n",
    "# Since we masked almost all of the year, our tolerance for missing data should be changed accordingly\n",
    "missing = \"at_least_n\"\n",
    "missing_options = {\"n\": 45}\n",
    "\n",
    "# We use xr.merge() to combine the results with the previous dataset.\n",
    "ds_4fa = xr.merge(\n",
    "    [\n",
    "        ds_4fa,\n",
    "        xh.indicators.get_yearly_op(\n",
    "            masked,\n",
    "            op=\"max\",\n",
    "            timeargs=timeargs_custom,\n",
    "            missing=missing,\n",
    "            missing_options=missing_options,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a daily volume from a daily streamflow\n",
    "ds[\"volume\"] = xh.indicators.compute_volume(ds[\"streamflow\"], out_units=\"hm3\")\n",
    "\n",
    "# We'll take slightly different indexers\n",
    "timeargs_vol = {\"spring\": {\"date_bounds\": [\"04-30\", \"06-15\"]}, \"annual\": {}}\n",
    "\n",
    "# The operation that we want here is the sum, not the max.\n",
    "ds_4fa = xr.merge(\n",
    "    [\n",
    "        ds_4fa,\n",
    "        xh.indicators.get_yearly_op(\n",
    "            ds,\n",
    "            op=\"sum\",\n",
    "            input_var=\"volume\",\n",
    "            timeargs=timeargs_vol,\n",
    "            missing=\"pct\",\n",
    "            missing_options={\"tolerance\": 0.15},\n",
    "            interpolate_na=True,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# for id in range(len(ds_4fa.coords[\"id\"])):\n",
    "#     print(ds_4fa.streamflow_max_spring[id,:].values)\n",
    "\n",
    "print(ds_4fa.streamflow_max_spring[0, :].values)\n",
    "\n",
    "# ds_4fa.streamflow_max_spring[1,:].values \n",
    "ds_4fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To speed up the Notebook, we'll only perform the analysis on a subset of variables\n",
    "params = xhfa.local.fit(\n",
    "    ds_4fa\n",
    ")\n",
    "print(params.streamflow_max_august[2,0,:].values.tolist())\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extreme_value_analysis.fit()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fit(ds_4fa, dist = \"gumbel_r\", method=\"bayes\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# xclim.stats.fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from lmoments3.distr import gev, gum, gpa\n",
    "stats.fit(ds_4fa, dist = \"genextreme\", method=\"bayes\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xhydro-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
