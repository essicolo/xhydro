{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "\n",
    "# Basic imports\n",
    "import hvplot.xarray\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xclim.indices.stats as stats  # not in original example\n",
    "import xdatasets as xd\n",
    "from scipy.stats import genextreme, genpareto, gumbel_r  # not in original example\n",
    "\n",
    "import xhydro_temp as xh\n",
    "import xhydro_temp.frequency_analysis as xhfa\n",
    "from xhydro_temp.extreme_value_analysis.parameterestimation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xhydro_temp.extreme_value_analysis.parameterestimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = (\n",
    "    xd.Query(\n",
    "        **{\n",
    "            \"datasets\": {\n",
    "                \"deh\": {\n",
    "                    \"id\": [\"020*\"],\n",
    "                    \"regulated\": [\"Natural\"],\n",
    "                    \"variables\": [\"streamflow\"],\n",
    "                }\n",
    "            },\n",
    "            \"time\": {\"start\": \"1970-01-01\", \"minimum_duration\": (15 * 365, \"d\")},\n",
    "        }\n",
    "    )\n",
    "    .data.squeeze()\n",
    "    .load()\n",
    ")\n",
    "\n",
    "# This dataset lacks some of the aforementioned attributes, so we need to add them.\n",
    "ds[\"id\"].attrs[\"cf_role\"] = \"timeseries_id\"\n",
    "ds[\"streamflow\"].attrs = {\n",
    "    \"long_name\": \"Streamflow\",\n",
    "    \"units\": \"m3 s-1\",\n",
    "    \"standard_name\": \"water_volume_transport_in_river_channel\",\n",
    "    \"cell_methods\": \"time: mean\",\n",
    "}\n",
    "\n",
    "# Some examples\n",
    "timeargs = {\n",
    "    \"spring\": {\"date_bounds\": [\"02-11\", \"06-19\"]},\n",
    "    \"summer\": {\"doy_bounds\": [152, 243]},\n",
    "    \"fall\": {\"month\": [9, 10, 11]},\n",
    "    \"winter\": {\n",
    "        \"season\": [\"DJF\"],\n",
    "        \"freq\": \"YS-DEC\",\n",
    "    },  # To correctly wrap around the year, we need to specify the resampling frequency.\n",
    "    \"august\": {\"month\": [8]},\n",
    "    \"annual\": {},\n",
    "}\n",
    "# Here, we hide years with more than 15% of missing data.\n",
    "ds_4fa = xh.indicators.get_yearly_op(\n",
    "    ds, op=\"max\", timeargs=timeargs, missing=\"pct\", missing_options={\"tolerance\": 0.15}\n",
    ")\n",
    "\n",
    "# Create a mask beforehand\n",
    "import random\n",
    "\n",
    "nyears = np.unique(ds.time.dt.year).size\n",
    "dom_start = xr.DataArray(\n",
    "    np.random.randint(1, 30, size=(nyears,)).astype(\"str\"),\n",
    "    dims=(\"year\"),\n",
    "    coords={\"year\": np.unique(ds.time.dt.year)},\n",
    ")\n",
    "dom_end = xr.DataArray(\n",
    "    np.random.randint(1, 30, size=(nyears,)).astype(\"str\"),\n",
    "    dims=(\"year\"),\n",
    "    coords={\"year\": np.unique(ds.time.dt.year)},\n",
    ")\n",
    "\n",
    "mask = xr.zeros_like(ds[\"streamflow\"])\n",
    "for y in dom_start.year.values:\n",
    "    # Random mask of dates per year, between April and June.\n",
    "    mask.loc[\n",
    "        {\n",
    "            \"time\": slice(\n",
    "                str(y) + \"-04-\" + str(dom_start.sel(year=y).item()),\n",
    "                str(y) + \"-06-\" + str(dom_end.sel(year=y).item()),\n",
    "            )\n",
    "        }\n",
    "    ] = 1\n",
    "# The name of the indexer will be used to identify the variable created here\n",
    "timeargs_custom = {\"custom\": {}}\n",
    "\n",
    "# We use where() to mask the data that we want to ignore\n",
    "masked = ds.where(mask == 1)\n",
    "# Since we masked almost all of the year, our tolerance for missing data should be changed accordingly\n",
    "missing = \"at_least_n\"\n",
    "missing_options = {\"n\": 45}\n",
    "\n",
    "# We use xr.merge() to combine the results with the previous dataset.\n",
    "ds_4fa = xr.merge(\n",
    "    [\n",
    "        ds_4fa,\n",
    "        xh.indicators.get_yearly_op(\n",
    "            masked,\n",
    "            op=\"max\",\n",
    "            timeargs=timeargs_custom,\n",
    "            missing=missing,\n",
    "            missing_options=missing_options,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# Get a daily volume from a daily streamflow\n",
    "ds[\"volume\"] = xh.indicators.compute_volume(ds[\"streamflow\"], out_units=\"hm3\")\n",
    "\n",
    "# We'll take slightly different indexers\n",
    "timeargs_vol = {\"spring\": {\"date_bounds\": [\"04-30\", \"06-15\"]}, \"annual\": {}}\n",
    "\n",
    "# The operation that we want here is the sum, not the max.\n",
    "ds_4fa = xr.merge(\n",
    "    [\n",
    "        ds_4fa,\n",
    "        xh.indicators.get_yearly_op(\n",
    "            ds,\n",
    "            op=\"sum\",\n",
    "            input_var=\"volume\",\n",
    "            timeargs=timeargs_vol,\n",
    "            missing=\"pct\",\n",
    "            missing_options={\"tolerance\": 0.15},\n",
    "            interpolate_na=True,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# for id in range(len(ds_4fa.coords[\"id\"])):\n",
    "#     print(ds_4fa.streamflow_max_spring[id,:].values)\n",
    "\n",
    "print(ds_4fa.streamflow_max_summer[0, :].values)\n",
    "\n",
    "ds_4fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "from xarray import open_zarr\n",
    "\n",
    "# path_hist = glob.glob(os.path.join(r\"C:\\Users\\KAMIL PC\\Desktop\\Life\\Stage\\Documents\\non_stationary_data\\eau_precpitable_CanESM5\"))\n",
    "path_hist = glob.glob(\n",
    "    os.path.join(\n",
    "        r\"C:\\Users\\HP\\Desktop\\Stage\\non_stationary_data\\eau_precpitable_CanESM5\"\n",
    "    )\n",
    ")\n",
    "\n",
    "ds_hist = open_zarr(path_hist[0], consolidated=True)\n",
    "ds_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extreme_value_analysis.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = fit(ds_4fa, dist=genextreme, method=\"ml\")\n",
    "# print(type(params.precipitable_water[:, 0, 0]))\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xclim.stats.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmoments3.distr import gev, gpa, gum\n",
    "\n",
    "params = stats.fit(ds_4fa, dist=gev, method=\"ml\")\n",
    "# print(type(params.precipitable_water[:, 0, 0]))\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# da = xr.DataArray(np.arange(125).reshape(5, 5, 5), dims=(\"x\", \"y\", \"z\"))\n",
    "# da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tgt_x = xr.DataArray(np.arange(0, 5), dims=\"points\")\n",
    "# tgt_y = xr.DataArray(np.arange(0, 5), dims=\"points\")\n",
    "# da2 = da.isel(x=2, y=2, z = 2)\n",
    "# da2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_extremes.precipitable_water.isel(y = 2, x = 2, dparams = 1, missing_dims = \"raise\")\n",
    "# params_extremes.precipitable_water[2, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cftime\n",
    "#\n",
    "# def convert_to_year_fraction(date: cftime.DatetimeNoLeap):\n",
    "#     year = date.year\n",
    "#     day_of_year = date.timetuple().tm_yday\n",
    "#     year_fraction = day_of_year / 365\n",
    "#     return year + year_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_values = [convert_to_year_fraction(date)  for date in ds_hist.time.values]\n",
    "# time_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = list(ds_hist.precipitable_water[:,0,0].values)\n",
    "# print(y)\n",
    "# gevfit(y, locationcov=[Variable(\"time\", time_values)])\n",
    "# # y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = Extremes.dataset(\"fremantle\")\n",
    "# from juliacall import convert as jl_convert\n",
    "#\n",
    "# fm = Extremes.gevfit(data, jl.Symbol(\"SeaLevel\"), locationcovid=jl_convert(jl.Vector[jl.Extremes.Symbol], [\"Year\", \"SOI\"]))\n",
    "#\n",
    "# params = (getattr(fm, \"θ̂\"))\n",
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = [\n",
    "#     31.4, 38.8, 63.78, 54.82, 123.2, 108.2, 108.1, 98.52,\n",
    "#     42.24, 33.45, 60.0, 84.23, 48.07, 77.71, 38.37, 42.02,\n",
    "#     46.0\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xhydro_temp.extreme_value_analysis.structures.conversions import *\n",
    "#\n",
    "# params = jl_matrix_tuple_to_py_list(Extremes.params(Extremes.gevfitbayes(py_list_to_jl_vector(y))))\n",
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [sum(x) / len(params) for x in zip(*params)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xhydro_temp.extreme_value_analysis"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
